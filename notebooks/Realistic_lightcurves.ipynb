{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import glob\n",
    "from astropy import log\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import copy\n",
    "from astropy.visualization import quantity_support\n",
    "from astropy.table import Table, QTable\n",
    "import matplotlib\n",
    "import astropy.units as u\n",
    "from astroduet.config import Telescope\n",
    "from astroduet.background import background_pixel_rate\n",
    "font = {'size'   : 22}\n",
    "from astroduet.models import Simulations, fits_file, load_model_ABmag, load_model_fluence\n",
    "matplotlib.rcParams.update({'font.size': 22})\n",
    "from astroduet.lightcurve import get_lightcurve, lightcurve_through_image\n",
    "import astroduet.image_utils\n",
    "from astroduet.utils import duet_fluence_to_abmag\n",
    "import seaborn as sns\n",
    "from scipy.interpolate import interp1d\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Do it only once\n",
    "# sims = Simulations()\n",
    "# sims.parse_emgw()\n",
    "# sims.parse_sne_bsg()\n",
    "# sims.parse_sne_ysg()\n",
    "# sims.parse_sne_rsg()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytime, ab1, ab2 = load_model_ABmag('ysg400',\n",
    "                                    dist=10 * u.Mpc)\n",
    "rtime, ab1, ab2 = load_model_ABmag('rsg400',\n",
    "                                    dist=10 * u.Mpc)\n",
    "btime, ab1, ab2 = load_model_ABmag('bsg80',\n",
    "                                    dist=10 * u.Mpc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btime[-1], ytime[-1], rtime[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_plot_lc(input_lc_file, distance=100e6*u.pc, **kwargs):\n",
    "    abtime, ab1, ab2 = load_model_ABmag(input_lc_file,\n",
    "                                        dist=distance)\n",
    "    model_lc_table_ab = QTable({'time': abtime, 'mag_D1': ab1, 'mag_D2':ab2})\n",
    "    lightcurve = get_lightcurve(input_lc_file, distance=distance, **kwargs)\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    gs = plt.GridSpec(1, 1, hspace=0)\n",
    "    ax0 = plt.subplot(gs[0])\n",
    "    good = (lightcurve['snr_D1'] > 1) | (lightcurve['snr_D2'] > 1)\n",
    "    lightcurve = lightcurve[good]\n",
    "    ax0.errorbar(lightcurve['time'].value / 86400, lightcurve['mag_D1'].value, \n",
    "                 fmt='o', markersize=2, yerr=lightcurve['mag_D1_err'].value, label='D1')\n",
    "    ax0.errorbar(lightcurve['time'].value / 86400, lightcurve['mag_D2'].value, \n",
    "                 fmt='o', markersize=2, yerr=lightcurve['mag_D2_err'].value, label='D2')\n",
    "    \n",
    "    ax0.plot(model_lc_table_ab['time'] / 86400, model_lc_table_ab[f'mag_D1'])\n",
    "    ax0.plot(model_lc_table_ab['time'] / 86400, model_lc_table_ab[f'mag_D2'])\n",
    "\n",
    "    ax0.set_ylabel(\"AB mag\")\n",
    "    ax0.set_xlabel(\"Time (d)\")\n",
    "    ax0.set_xlim([lightcurve['time'][0].value / 86400, lightcurve['time'][-1].value / 86400])\n",
    "    ymin = min(lightcurve['mag_D1'].value.min(), lightcurve['mag_D2'].value.min()) - 1\n",
    "    ymax = max(lightcurve['mag_D1'].value.max(), lightcurve['mag_D2'].value.max()) + 1\n",
    "    # Inverted ax for magnitude\n",
    "    ax0.set_ylim([ymax, ymin])\n",
    "#    ax1.semilogx();\n",
    "    ax0.legend()\n",
    "    \n",
    "    \n",
    "def create_and_plot_lc_snr(input_lc_file, distance=100e6*u.pc, **kwargs):\n",
    "    abtime, ab1, ab2 = load_model_ABmag(input_lc_file,\n",
    "                                        dist=distance)\n",
    "    model_lc_table_ab = QTable({'time': abtime, 'mag_D1': ab1, 'mag_D2':ab2})\n",
    "    lightcurve = get_lightcurve(input_lc_file, distance=distance, **kwargs)\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    gs = plt.GridSpec(2, 1, hspace=0)\n",
    "    ax0 = plt.subplot(gs[0])\n",
    "    ax1 = plt.subplot(gs[1], sharex=ax0)\n",
    "    good = (lightcurve['snr_D1'] > 1) | (lightcurve['snr_D2'] > 1)\n",
    "    lightcurve = lightcurve[good]\n",
    "    ax0.errorbar(lightcurve['time'].value / 86400, lightcurve['mag_D1'].value, \n",
    "                 fmt='o', markersize=2, yerr=lightcurve['mag_D1_err'].value, label='D1')\n",
    "    ax0.errorbar(lightcurve['time'].value / 86400, lightcurve['mag_D2'].value, \n",
    "                 fmt='o', markersize=2, yerr=lightcurve['mag_D2_err'].value, label='D2')\n",
    "    ax1.scatter(lightcurve['time'].value / 86400, lightcurve['snr_D1'].value, s=2)\n",
    "    ax1.scatter(lightcurve['time'].value / 86400, lightcurve['snr_D2'].value, s=2)\n",
    "    \n",
    "    ax0.plot(model_lc_table_ab['time'] / 86400, model_lc_table_ab[f'mag_D1'])\n",
    "    ax0.plot(model_lc_table_ab['time'] / 86400, model_lc_table_ab[f'mag_D2'])\n",
    "\n",
    "    ax0.set_ylabel(\"AB mag\")\n",
    "    ax1.set_ylabel(\"S/R\")\n",
    "    ax1.set_xlabel(\"Time (d)\")\n",
    "    ax0.set_xlim([lightcurve['time'][0].value / 86400, lightcurve['time'][-1].value / 86400])\n",
    "    ymin = min(lightcurve['mag_D1'].value.min(), lightcurve['mag_D2'].value.min()) - 1\n",
    "    ymax = max(lightcurve['mag_D1'].value.max(), lightcurve['mag_D2'].value.max()) + 1\n",
    "    # Inverted ax for magnitude\n",
    "    ax0.set_ylim([ymax, ymin])\n",
    "#    ax1.semilogx();\n",
    "    ax0.legend()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_and_plot_lc('rsg600', distance=500*u.Mpc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_and_plot_lc('rsg400', distance=300*u.Mpc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now specifying the observing window..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_galaxy(distance, duet, tolerance=10 * u.Mpc, average_gal=False):\n",
    "    from astroduet.models import load_bai\n",
    "    from astropy.table import QTable\n",
    "    from astroduet.utils import galex_to_duet\n",
    "    bai = QTable(load_bai())\n",
    "    bai['BAI1'], bai['BAI2'] = galex_to_duet([bai['SURFFUV'].value, bai['SURFNUV'].value], duet=duet)\n",
    "    oversample = 6\n",
    "    pixel_size_init = duet.pixel / oversample\n",
    "    galaxies_within_distance = \\\n",
    "        (bai['DIST'] >= distance - tolerance)&(bai['DIST'] < distance + tolerance)\n",
    "    if not np.any(galaxies_within_distance):\n",
    "        log.warn(f\"No galaxies in BAI catalogue between \"\n",
    "                 f\"{(distance - tolerance).to(u.Mpc).value:.2f} \"\n",
    "                 f\"and {(distance + tolerance).to(u.Mpc).value:.2f} Mpc.\"\n",
    "                 \" Choosing randomly from sample > 150 Mpc\")\n",
    "        galaxies_within_distance = bai['DIST'] > 150 * u.Mpc\n",
    "    \n",
    "    galaxy = np.random.choice(bai[galaxies_within_distance])\n",
    "    \n",
    "    rad = (galaxy['RAD'] * u.arcsec * galaxy['DIST'] * u.Mpc / distance).to(u.arcsec)\n",
    "    rad_pix = rad / pixel_size_init\n",
    "\n",
    "    if galaxy['MORPH'] >=0: \n",
    "        n=1\n",
    "    else: \n",
    "        n = 4\n",
    "    theta = np.random.uniform(0, np.pi)\n",
    "    ellip = np.random.uniform(0.1, 1)\n",
    "    pos = np.random.uniform(0.1, 3)\n",
    "    if average_gal:\n",
    "        pos = 1\n",
    "        galaxy['BAI1'] = np.median(bai['BAI1'])\n",
    "        galaxy['BAI2'] = np.median(bai['BAI2'])\n",
    "    d = pos * rad / pixel_size_init\n",
    "    x_0 = d * np.cos(theta)\n",
    "    y_0 = d * np.sin(theta)\n",
    "    \n",
    "    gal_params = dict(r_eff=rad_pix.value, n=n, theta=theta, ellip=ellip, x_0=x_0.value, y_0=y_0.value)\n",
    "    gal_params1 = {'magnitude': galaxy['BAI1'], **gal_params}\n",
    "    gal_params2 = {'magnitude': galaxy['BAI2'], **gal_params}\n",
    "    return gal_params1, gal_params2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def red_chi_sq(f, x, s, dof=None):\n",
    "    if dof is None:\n",
    "        dof = len(f) - 1\n",
    "    return np.sum((f - x)**2 / s**2) / dof\n",
    "\n",
    "\n",
    "def plot_realistic_lightcurve(input_lc_file, exposure, label=None, debug=False,  \n",
    "                              observing_windows=np.array([[0, 30000]]) * u.s, \n",
    "                              final_resolution=1200 * u.s, distance=150e6*u.pc,\n",
    "                              galaxy_type=None, psf_correction = 0.937,\n",
    "                              show_non_rebinned=False):\n",
    "    duet = Telescope()\n",
    "    # Set debug to True to dump all intermediate images.\n",
    "    galaxy_par = None\n",
    "    if galaxy_type == \"random\":\n",
    "        galaxy_par = get_random_galaxy(distance, duet)[0]\n",
    "        galaxy_type = \"custom\"\n",
    "    elif galaxy_type == \"average\":\n",
    "        galaxy_par = get_random_galaxy(distance, duet, average_gal=True)[0]\n",
    "        galaxy_type = \"custom\"\n",
    "\n",
    "    lightcurve_init = \\\n",
    "        get_lightcurve(input_lc_file, exposure=exposure, observing_windows=observing_windows,\n",
    "                       distance=distance)\n",
    "    lightcurve_rebin = lightcurve_through_image(lightcurve_init, exposure=exposure, \n",
    "                                                final_resolution=final_resolution, \n",
    "                                                debug=debug, gal_params=galaxy_par, gal_type=galaxy_type)\n",
    "    if show_non_rebinned:\n",
    "        lightcurve = lightcurve_through_image(lightcurve_init, exposure=exposure, debug=debug,\n",
    "                                              gal_params=galaxy_par, gal_type=galaxy_type)\n",
    "\n",
    "    model_lc_table_fl = QTable(load_model_fluence(input_lc_file,\n",
    "                                                  dist=distance))\n",
    "    \n",
    "    model_lc_table_AB = QTable(load_model_ABmag(input_lc_file,\n",
    "                                                dist=distance))\n",
    "    \n",
    "    model_lc_table_fl['fluence_D1'] = model_lc_table_fl['fluence_D1'].to(u.ph / u.cm**2 / u.s)\n",
    "    model_lc_table_fl['fluence_D2'] = model_lc_table_fl['fluence_D2'].to(u.ph / u.cm**2 / u.s)\n",
    "    \n",
    "    model_fun_D1 = interp1d(model_lc_table_fl['time'], model_lc_table_fl['fluence_D1'], bounds_error=False, fill_value='extrapolate')\n",
    "    model_fun_D2 = interp1d(model_lc_table_fl['time'], model_lc_table_fl['fluence_D2'], bounds_error=False, fill_value='extrapolate')\n",
    "\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    gs = plt.GridSpec(2, 1, hspace=0)\n",
    "    ax0 = plt.subplot(gs[0])\n",
    "    ax1 = plt.subplot(gs[1], sharex=ax0)\n",
    "    plt.suptitle(label)\n",
    "\n",
    "    ax0.plot(model_lc_table_fl['time'].value / 86400, \n",
    "             model_lc_table_fl['fluence_D1'].to(u.ph / u.cm**2 / u.s).value, label=f\"init D1\",\n",
    "             color='r')\n",
    "    ax0.plot(model_lc_table_fl['time'].value / 86400, \n",
    "            model_lc_table_fl['fluence_D2'].to(u.ph / u.cm**2 / u.s).value, label=f\"init D2\",\n",
    "             color='b')\n",
    "    ax1.axhline(0, color='k', ls='--')\n",
    "      \n",
    "    model_lc_table_fl.write(label + '_model.csv')\n",
    "    model_lc_table_AB.write(label + '_modelAB.csv')\n",
    "    if not show_non_rebinned:\n",
    "        lightcurves = [lightcurve_rebin]\n",
    "        exposures = [final_resolution]\n",
    "        filenames = [label + '_rebin.csv']\n",
    "    else:\n",
    "        lightcurves = [lightcurve, lightcurve_rebin]\n",
    "        exposures = [exposure, final_resolution]\n",
    "        filenames = [label + '.csv', label + '_rebin.csv']\n",
    "    \n",
    "    for lc, expo, filename in zip(lightcurves, exposures, filenames):\n",
    "        alpha = 1\n",
    "        size = 10\n",
    "        if expo == exposure:\n",
    "            alpha = 0.3\n",
    "            size = 5\n",
    "        print(lc, expo, filename)\n",
    "        good1 = (lc['fluence_D1_fit'] > 0)&(lc['fluence_D1_fiterr'] < lc['fluence_D1_fit'])&(lc['fluence_D1_fiterr'] > 0)\n",
    "        good2 = (lc['fluence_D2_fit'] > 0)&(lc['fluence_D2_fiterr'] < lc['fluence_D2_fit'])&(lc['fluence_D2_fiterr'] > 0)\n",
    "        good = good1&good2\n",
    "        \n",
    "        redchi = red_chi_sq(lc['fluence_D1_fit'][good].value / psf_correction, \n",
    "                            model_fun_D1(lc['time'].value[good]), \n",
    "                            lc['fluence_D1_fiterr'][good].value)\n",
    "        ax0.errorbar(lc['time'].value[good] / 86400, \n",
    "                     lc['fluence_D1_fit'][good].value / psf_correction, \n",
    "                     yerr=lc['fluence_D1_fiterr'][good].value, fmt='o', label=f\"D1, {expo}, {redchi:.2f}\",\n",
    "                     alpha=alpha, color='r', markersize=size)\n",
    "        \n",
    "        redchi = red_chi_sq(lc['fluence_D2_fit'][good].value / psf_correction, \n",
    "                            model_fun_D2(lc['time'].value[good]), \n",
    "                            lc['fluence_D2_fiterr'][good].value)\n",
    "        ax0.errorbar(lc['time'].value[good] / 86400, \n",
    "                     lc['fluence_D2_fit'][good].value / psf_correction, \n",
    "                     yerr=lc['fluence_D2_fiterr'][good].value, fmt='s', label=f\"D2, {expo}, {redchi:.2f}\",\n",
    "                     alpha=alpha, color='b', markersize=size)\n",
    "        \n",
    "        ax1.errorbar(lc['time'].value[good] / 86400, \n",
    "                     lc['fluence_D1_fit'][good].value / psf_correction - model_fun_D1(lc['time'].value[good]), \n",
    "                     yerr=lc['fluence_D1_fiterr'][good].value, fmt='o',\n",
    "                     alpha=alpha, color='r', markersize=size)\n",
    "        ax1.errorbar(lc['time'].value[good] / 86400, \n",
    "                     lc['fluence_D2_fit'][good].value / psf_correction - model_fun_D2(lc['time'].value[good]), \n",
    "                     yerr=lc['fluence_D2_fiterr'][good].value, fmt='s', \n",
    "                     alpha=alpha, color='b', markersize=size)\n",
    "        \n",
    "        lc[good].write(filename)\n",
    "\n",
    "    ax0.set_xlabel(\"Time (d)\")\n",
    "    ax0.set_ylabel(\"Fluence (ph / cm^2 / s)\")\n",
    "    ax0.set_xlim([lightcurve_rebin['time'].value.min()/86400 - 0.1, \n",
    "              lightcurve_rebin['time'].value.max()/86400 + 0.1])\n",
    "    \n",
    "    ref_err = np.median(lightcurve_rebin['fluence_D1_fiterr'][lightcurve_rebin['fluence_D1_fiterr'].value > 0]).value\n",
    "    ax1.set_ylim([-ref_err * 10, ref_err * 10])\n",
    "    \n",
    "    ax0.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average host:\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for dist_mpc in range(100, 600, 100):\n",
    "    for model in [\"kilonova_0.04.dat\", \"shock_5e10.dat\"]:\n",
    "        plot_realistic_lightcurve(model, 300 * u.s,  \n",
    "                                  observing_windows=np.array([[0, 86400]]) * u.s, \n",
    "                                  final_resolution=2400 * u.s, \n",
    "                                  distance=dist_mpc*u.Mpc, label=f\"{model}, {dist_mpc}Mpc\", debug=True,\n",
    "                                  show_non_rebinned=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for dist_mpc in range(50, 200, 50):\n",
    "    for model in [\"kilonova_0.04.dat\", \"shock_5e10.dat\"]:\n",
    "        plot_realistic_lightcurve(model, 300 * u.s,  \n",
    "                                  observing_windows=np.array([[0, 86400]]) * u.s, \n",
    "                                  final_resolution=2400 * u.s, \n",
    "                                  distance=dist_mpc*u.Mpc, label=f\"{model}, {dist_mpc}Mpc - galaxy\", debug=True,\n",
    "                                  show_non_rebinned=True, galaxy_type='average')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_realistic_lightcurve(\"shock_5e10.dat\", 300 * u.s,  \n",
    "                          observing_windows=np.array([[30 * 60, 30000]]) * u.s, \n",
    "                          final_resolution=2400 * u.s, \n",
    "                          distance=70e6*u.pc, label=\"shock_5e10, 70Mpc\", debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_realistic_lightcurve(\"shock_5e10.dat\", 300 * u.s,  \n",
    "                          observing_windows=np.array([[30 * 60, 30000]]) * u.s, \n",
    "                          final_resolution=2400 * u.s, \n",
    "                          distance=70e6*u.pc, label=\"shock_5e10, 70Mpc, with galaxy\", debug=True,\n",
    "                          galaxy_type=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_realistic_lightcurve(\"kilonova_0.04.dat\", 300 * u.s,  \n",
    "                          observing_windows=np.array([[30 * 60, 900000]]) * u.s, \n",
    "                          final_resolution=4800 * u.s, \n",
    "                          distance=150e6*u.pc, label=\"blukn_04, 150Mpc\", debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_realistic_lightcurve(\"rsg400\", 300 * u.s,  \n",
    "                          observing_windows=np.array([[0, 500000]]) * u.s, \n",
    "                          final_resolution=1200 * u.s, \n",
    "                          distance=200*u.Mpc, label=\"RSG 400 Ro, 200Mpc\", debug=True,\n",
    "                          show_non_rebinned=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_realistic_lightcurve(\"ysg400\", 300 * u.s,  \n",
    "                          observing_windows=np.array([[0, 500000]]) * u.s, \n",
    "                          final_resolution=1200 * u.s, \n",
    "                          distance=200*u.Mpc, label=\"YSG 400 Ro, 200Mpc\", debug=True,\n",
    "                          show_non_rebinned=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for dist_mpc in [100, 150, 200]:\n",
    "    for model in ['bsg80', 'rsg400', 'ysg400']:\n",
    "        star = model.upper().replace('SG', 'SG ')\n",
    "        plot_realistic_lightcurve(model, 300 * u.s,  \n",
    "                                  observing_windows=np.array([[0, 500000]]) * u.s, \n",
    "                                  final_resolution=2400 * u.s, \n",
    "                                  distance=dist_mpc*u.Mpc, label=f\"{star} Ro, {dist_mpc}Mpc\", debug=True,\n",
    "                                  show_non_rebinned=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dist_mpc in [300, 400, 500]:\n",
    "    for model in ['bsg80', 'rsg400', 'ysg400']:\n",
    "        star = model.upper().replace('SG', 'SG ')\n",
    "        plot_realistic_lightcurve(model, 300 * u.s,  \n",
    "                                  observing_windows=np.array([[0, 500000]]) * u.s, \n",
    "                                  final_resolution=2400 * u.s, \n",
    "                                  distance=dist_mpc*u.Mpc, label=f\"{star} Ro, {dist_mpc}Mpc\", debug=True,\n",
    "                                  show_non_rebinned=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for dist_mpc in [600, 700, 800]:\n",
    "    for model in ['bsg80', 'rsg400', 'ysg400']:\n",
    "        star = model.upper().replace('SG', 'SG ')\n",
    "        plot_realistic_lightcurve(model, 300 * u.s,  \n",
    "                                  observing_windows=np.array([[0, 500000]]) * u.s, \n",
    "                                  final_resolution=2400 * u.s, \n",
    "                                  distance=dist_mpc*u.Mpc, label=f\"{star} Ro, {dist_mpc}Mpc\", debug=True,\n",
    "                                  show_non_rebinned=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_realistic_lightcurve(\"rsg600\", 300 * u.s,  \n",
    "                          observing_windows=np.array([[0, 500000]]) * u.s, \n",
    "                          final_resolution=1500 * u.s, \n",
    "                          distance=370e6*u.pc, label=\"RSG 600 Ro, 370Mpc\", debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## In case someone wants to take a look at the debug images...\n",
    "## set debug=True in plot_realistic_lightcurves and look at them\n",
    "\n",
    "def plot_debug_images(directory):\n",
    "    import matplotlib.animation as animation\n",
    "    from astroduet.image_utils import find, run_daophot\n",
    "    from statsmodels.robust import mad\n",
    "    img_pickles = glob.glob(os.path.join(directory, '*.p'))\n",
    "    for img_pickle in img_pickles:\n",
    "        with open(img_pickle, 'rb') as fobj:\n",
    "            img = pickle.load(fobj)\n",
    "        image1 = img['imgD1']\n",
    " \n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.title(img_pickle)\n",
    "        plt.imshow(image1.value)\n",
    "        plt.colorbar()\n",
    "        if 'ref' in img_pickle:\n",
    "            ref_img = image1.value\n",
    "    \n",
    "    img_lc = Table.read(os.path.join(directory,'lightcurve.hdf5'))\n",
    "    \n",
    "    for line in img_lc:\n",
    "        im = line['imgs_D1_bkgsub']\n",
    "        time = line['time']\n",
    "        fig = plt.figure(figsize=(3, 3))\n",
    "        diff = im - ref_img\n",
    "        plt.imshow(diff - np.median(diff), vmin=0, vmax=5* mad(diff.flatten()))\n",
    "        plt.title(time)\n",
    "\n",
    "plot_debug_images('debug_imgs_33386538')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_lightcurve(lightcurve, label='lightcurve fit', solutions=None,\n",
    "                   debug=False, additional_info_for_table=None,\n",
    "                   fit_model_files=None, correct_model=\"\", distance=None, \n",
    "                   psf_correction = 0.937):\n",
    "    from astroduet.models import Simulations\n",
    "    from scipy.optimize import curve_fit\n",
    "    from scipy.interpolate import interp1d\n",
    "    from astropy.visualization import quantity_support\n",
    "    quantity_support()\n",
    "    if additional_info_for_table is None:\n",
    "        additional_info_for_table = {}\n",
    "    if distance is None:\n",
    "        distance = 100 * u.Mpc\n",
    "    if solutions is None:\n",
    "        add_names = [k for k, v in additional_info_for_table.items()]\n",
    "        add_dtypes = [np.asarray(v).dtype if 'model' not in k else 'U30' for k, v in additional_info_for_table.items()]\n",
    "        names = 'fit_model,D1,D2,ratio,D1_chisq,D2_chisq,ratio_chisq,D1_chisq_nofit,D2_chisq_nofit,ratio_chisq_nofit,ngood'.split(',') + add_names\n",
    "        dtypes = dtype=['U30', float, float, float, float, float, float, float, float, float, int] + add_dtypes\n",
    "            \n",
    "        solutions = QTable(\n",
    "            names=names, \n",
    "            dtype=dtypes)\n",
    "    \n",
    "    if fit_model_files is not None:\n",
    "        lc_files = fit_model_files\n",
    "    else:\n",
    "        lc_files = Simulations().emgw_simulations\n",
    "\n",
    "    fluence_D1 = lightcurve['fluence_D1_fit'] / psf_correction\n",
    "    fluence_D2 = lightcurve['fluence_D2_fit'] / psf_correction\n",
    "    snr_D1 = lightcurve['snr_D1']\n",
    "    snr_D2 = lightcurve['snr_D2']\n",
    "    good = ((fluence_D1 > 0)&(snr_D1 > 5))|((fluence_D2 > 0)&(snr_D2 > 5))\n",
    "    \n",
    "    lightcurve = lightcurve[good]\n",
    "    if len(lightcurve) < 5:\n",
    "        print(\"Lightcurve is invalid\")\n",
    "        for lc_file in lc_files:\n",
    "            empty_row_dict = {'fit_model': lc_file, 'D1': 0, 'D2': 0, 'ratio': 0, \n",
    "                              'D1_chisq': -1, 'D2_chisq': -1, 'ratio_chisq': -1,\n",
    "                              'D1_chisq_nofit': -1, 'D2_chisq_nofit': -1, 'ratio_chisq_nofit': -1,\n",
    "                              'ngood': 0}\n",
    "            solutions.add_row({**empty_row_dict,**additional_info_for_table})\n",
    "        return solutions\n",
    "    \n",
    "    times = lightcurve['time']\n",
    "    fluence_D1 = lightcurve['fluence_D1_fit'] / psf_correction\n",
    "    fluence_D2 = lightcurve['fluence_D2_fit'] / psf_correction\n",
    "    snr_D1 = lightcurve['snr_D1']\n",
    "    snr_D2 = lightcurve['snr_D2']\n",
    "    fluence_D1_err = lightcurve['fluence_D1_fiterr'] / psf_correction\n",
    "    fluence_D2_err = lightcurve['fluence_D2_fiterr'] / psf_correction\n",
    "\n",
    "    ratio = fluence_D2 / fluence_D1\n",
    "    ratio_err = ratio * (fluence_D1_err / fluence_D1 +\n",
    "                         fluence_D2_err / fluence_D2)\n",
    "    \n",
    "    if debug:\n",
    "        plt.figure(figsize=(15, 15))\n",
    "        plt.suptitle(label)\n",
    "        gs = plt.GridSpec(3, 1)\n",
    "        ax1 = plt.subplot(gs[0])\n",
    "        ax2 = plt.subplot(gs[1], sharex=ax1)\n",
    "        axr = plt.subplot(gs[2], sharex=ax1)\n",
    "        ax1.errorbar(times, fluence_D1, yerr=fluence_D1_err, fmt='o', markersize=5, label='data')\n",
    "        ax2.errorbar(times, fluence_D2, yerr=fluence_D2_err, fmt='o', markersize=5, label='data')\n",
    "        axr.errorbar(times, ratio, yerr=ratio_err, fmt='o', markersize=5, label='data')\n",
    "\n",
    "    for lc_file in lc_files[::]:\n",
    "        model_lc_table_fl = QTable(load_model_fluence(lc_file, dist=distance))\n",
    "        interpolated_lc_1 = interp1d(model_lc_table_fl['time'].to(u.s).value,\n",
    "                           model_lc_table_fl['fluence_D1'].value, fill_value=0,\n",
    "                           bounds_error=False)\n",
    "        interpolated_lc_2 = interp1d(model_lc_table_fl['time'].to(u.s).value,\n",
    "                           model_lc_table_fl['fluence_D2'].value, fill_value=0,\n",
    "                           bounds_error=False)\n",
    "        def interpolated_lc_ratio(time):\n",
    "            return(interpolated_lc_2(time) / interpolated_lc_1(time))\n",
    "    \n",
    "        def constant_fit_fun_1(x, a):\n",
    "            return a * interpolated_lc_1(x)\n",
    "        def constant_fit_fun_2(x, a):\n",
    "            return a * interpolated_lc_2(x)\n",
    "        def constant_fit_fun_ratio(x, a):\n",
    "            return a * interpolated_lc_ratio(x)\n",
    "        \n",
    "        d1_chisq_nofit = red_chi_sq(constant_fit_fun_1(times, 1), \n",
    "                              fluence_D1.value, fluence_D1_err.value, dof=len(fluence_D1) - 1)\n",
    "        d2_chisq_nofit = red_chi_sq(constant_fit_fun_2(times, 1), \n",
    "                              fluence_D2.value, fluence_D2_err.value, dof=len(fluence_D2) - 1)\n",
    "        ratio_chisq_nofit = red_chi_sq(constant_fit_fun_ratio(times, 1), \n",
    "                              ratio.value, ratio_err.value, dof=len(ratio) - 1)\n",
    "\n",
    "        par1, pcov1 = curve_fit(constant_fit_fun_1, \n",
    "                                times, fluence_D1, \n",
    "                                sigma=fluence_D1_err, p0=[1])\n",
    "        par2, pcov2 = curve_fit(constant_fit_fun_2, \n",
    "                                times, fluence_D2, \n",
    "                                sigma=fluence_D2_err, p0=[1])\n",
    "        parr, pcovr = curve_fit(constant_fit_fun_ratio, \n",
    "                                times, ratio, sigma=ratio_err, p0=[1])\n",
    "        \n",
    "        d1_chisq = red_chi_sq(constant_fit_fun_1(times, *par1), \n",
    "                              fluence_D1.value, fluence_D1_err.value, dof=len(fluence_D1) - 1)\n",
    "        d2_chisq = red_chi_sq(constant_fit_fun_2(times, *par2), \n",
    "                              fluence_D2.value, fluence_D2_err.value, dof=len(fluence_D2) - 1)\n",
    "        ratio_chisq = red_chi_sq(constant_fit_fun_ratio(times, *parr), \n",
    "                              ratio.value, ratio_err.value, dof=len(ratio) - 1)\n",
    "        new_row = {'fit_model': lc_file, 'D1': par1, 'D2': par2, 'ratio': parr, \n",
    "                   'D1_chisq': d1_chisq, 'D2_chisq': d2_chisq, 'ratio_chisq': ratio_chisq,\n",
    "                   'D1_chisq_nofit': d1_chisq_nofit, 'D2_chisq_nofit': d2_chisq_nofit, 'ratio_chisq_nofit': ratio_chisq_nofit,\n",
    "                   'ngood': len(fluence_D1)}\n",
    "        solutions.add_row({**new_row, **additional_info_for_table})\n",
    "        if debug:\n",
    "            fine_times = np.linspace(times[0], times[-1], 1000)\n",
    "            alpha = 0.3\n",
    "            lw = 0.5\n",
    "            if lc_file.replace('.dat', '') == correct_model.replace('.dat', ''):\n",
    "                alpha, lw = 1, 1\n",
    "                \n",
    "            ax1.plot(fine_times, \n",
    "                     constant_fit_fun_1(fine_times, *par1), color='k', alpha=alpha, lw=lw, markersize=0)\n",
    "            ax2.plot(fine_times, \n",
    "                     constant_fit_fun_2(fine_times, *par2), color='k', alpha=alpha, lw=lw, markersize=0)\n",
    "            axr.plot(fine_times, \n",
    "                     constant_fit_fun_ratio(fine_times, *parr), color='k', alpha=alpha, lw=lw, markersize=0)\n",
    "            if correct_model in lc_file:\n",
    "                ax1.plot(fine_times, \n",
    "                         constant_fit_fun_1(fine_times, 1), label=correct_model, color='b', lw=1, markersize=0)\n",
    "                ax2.plot(fine_times, \n",
    "                         constant_fit_fun_2(fine_times, 1), label=correct_model, color='b', lw=1, markersize=0)\n",
    "                axr.plot(fine_times, \n",
    "                         constant_fit_fun_ratio(fine_times, 1), label=correct_model, color='b', lw=1, markersize=0)\n",
    "                \n",
    "\n",
    "    if debug:\n",
    "        axr.set_ylabel('Flux ratio')\n",
    "        ax1.legend()\n",
    "        print(\"Debug done\")\n",
    "        plt.show()\n",
    "\n",
    "    return solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_and_fit(model, observing_windows = np.array([[0, 86400 * 5]]) * u.s, distance = 200 * u.Mpc):\n",
    "    s = Simulations()\n",
    "    \n",
    "    lightcurve_init = \\\n",
    "        get_lightcurve(model, exposure=100*u.s,  \n",
    "                       observing_windows=observing_windows,\n",
    "                       distance=distance)\n",
    "    lightcurve_rebin = lightcurve_through_image(lightcurve_init, exposure=300*u.s, \n",
    "                                                final_resolution=1200*u.s, \n",
    "                                                silent=True)\n",
    "\n",
    "    solutions = fit_lightcurve(lightcurve_rebin, label=f'{model}, {distance.to(u.Mpc).value} Mpc', \n",
    "                               debug=True, \n",
    "                               fit_model_files=s.sne_bsg_simulations + s.sne_rsg_simulations + s.sne_ysg_simulations,\n",
    "                               correct_model=model, distance=distance, psf_correction = 0.937)\n",
    "    \n",
    "simulate_and_fit('bsg80')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulate_and_fit('rsg600', distance = 600 * u.Mpc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulate_and_fit('rsg600', distance = 500 * u.Mpc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulate_and_fit('ysg400')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightcurve_init = \\\n",
    "    get_lightcurve('kilonova_0.04.dat', exposure=300*u.s,  \n",
    "                   observing_windows=np.array([[1800, 40000]]) * u.s,\n",
    "                   distance=100*u.Mpc)\n",
    "lightcurve_rebin = lightcurve_through_image(lightcurve_init, exposure=300*u.s, \n",
    "                                            final_resolution=6000*u.s, \n",
    "                                            silent=True)\n",
    "\n",
    "solutions = fit_lightcurve(lightcurve_rebin, label='kilonova_0.04.dat - 100 Mpc', \n",
    "                       debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rebinned_lightcurve_fit(input_lc_file, exposure, label=None, debug=False,  \n",
    "                            observing_windows=np.array([[1800, 30000]]) * u.s, \n",
    "                            final_resolution=1200 * u.s, distance=100e6*u.pc,\n",
    "                            ntrial=100, outfile=None):\n",
    "    import seaborn as sns\n",
    "    import tqdm\n",
    "    from astroduet.utils import suppress_stdout\n",
    "    if outfile is not None and os.path.exists(outfile):\n",
    "        solutions = Table.read(outfile)\n",
    "    else:\n",
    "        solutions = None\n",
    "    for i in tqdm.tqdm(range(ntrial)):\n",
    "        try:\n",
    "            with suppress_stdout():\n",
    "                lightcurve_init = \\\n",
    "                    get_lightcurve(input_lc_file, exposure=exposure, observing_windows=observing_windows,\n",
    "                                   distance=distance)\n",
    "\n",
    "                lightcurve_rebin = lightcurve_through_image(lightcurve_init, exposure=exposure, \n",
    "                                                                final_resolution=final_resolution, \n",
    "                                                                debug=debug, silent=True)\n",
    "        \n",
    "            solutions = fit_lightcurve(lightcurve_rebin, label=input_lc_file, solutions=solutions,\n",
    "                                       debug=False)\n",
    "        except Exception as e:\n",
    "            print(\"An exception occurred. Intermediate results are saved in the solution Table\")\n",
    "            print(e)\n",
    "            break\n",
    "            \n",
    "    if outfile is not None:\n",
    "        solutions.write(outfile, overwrite=True)\n",
    "\n",
    "    return solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------**Uncomment below to produce the data**------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solutions_sh510_30 = get_rebinned_lightcurve_fit('shock_5e10.dat', exposure=300 * u.s,\n",
    "#                         observing_windows=np.array([[1800, 30000]]) * u.s,\n",
    "#                         distance=200 * u.Mpc, ntrial=100)\n",
    "\n",
    "# sns.pairplot(solutions_sh510_30.to_pandas(), hue='model', diag_kind=\"kde\", vars='D1_chisq,D2_chisq,ratio_chisq'.split(','))\n",
    "# solutions_sh510_30.write('solutions_sh510.csv', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure description: The fits with low chi squared are systematically those to the correct model (in this case, a shock-type GRB). We generated 30 light curves corresponding to the model `shock_5e10`, at 200 Mpc, starting 30 minutes after the event, and including all instrumental and zodiacal noise sources, and fitted it with all six GW models. The best-fit on the D1 and D2 light curve (as measured from low values of $\\chi^2$) is systematically the one corresponding to the correct model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ntrial = 10\n",
    "while 1:\n",
    "    solutions_sh510 = get_rebinned_lightcurve_fit('shock_5e10.dat', exposure=300 * u.s,\n",
    "                        observing_windows=np.array([[1800, 30000]]) * u.s,\n",
    "                        distance=200 * u.Mpc, ntrial=ntrial, outfile='solutions_sh510.csv')\n",
    "\n",
    "    solutions_k04 = get_rebinned_lightcurve_fit('kilonova_0.04.dat', exposure=300 * u.s,\n",
    "                            observing_windows=np.array([[1800, 40000]]) * u.s,\n",
    "                            final_resolution=6000 * u.s,\n",
    "                           distance=130*u.Mpc, ntrial=ntrial, outfile='solutions_k04.csv')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(solutions_sh510.to_pandas(), hue='model', diag_kind=\"kde\", vars='D1_chisq,D2_chisq,ratio_chisq'.split(','))\n",
    "sns.pairplot(solutions_k04.to_pandas(), hue='model', diag_kind=\"kde\", vars='D1_chisq,D2_chisq,ratio_chisq'.split(','))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure description: Same as previous figure, but this time we simulated 30 lightcurves corresponding to the model `kilonova_0.04`, at 150 Mpc, starting 30 minutes after the event, including all instrumental and zodiacal noise sources, and fitted it with all six GW models. The best-fit on the D1 and D2 light curve (as measured from low values of $\\chi^2$), in this case, separates kilonova models from shock GRB models but not much different kilonova models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_distributions(solutions, correct, label=None, nbins=10):\n",
    "    plt.figure(figsize=(15,15))\n",
    "    plt.suptitle(label)\n",
    "    gs = plt.GridSpec(4, 1, height_ratios=(4, 3, 4, 3), hspace=0)\n",
    "    ax11 = plt.subplot(gs[0])\n",
    "    ax12 = plt.subplot(gs[1], sharex=ax11)\n",
    "    ax21 = plt.subplot(gs[2], sharex=ax11)\n",
    "    ax22 = plt.subplot(gs[3], sharex=ax11)\n",
    "    good = (solutions['D1_chisq'] < 1e32)&(solutions['D2_chisq'] < 1e32)&(solutions['ngood'] >= 4)\n",
    "    solutions = solutions[good]\n",
    "\n",
    "    if correct is not None:\n",
    "        ax1 = ax11\n",
    "        ax2 = ax21\n",
    "        good = solutions['model'] == correct\n",
    "        sol = solutions[good]\n",
    "        per_99_1 = np.percentile(sol['D1_chisq'], 99)\n",
    "        per_99_2 = np.percentile(sol['D2_chisq'], 99)\n",
    "        ax1.hist(sol['D1_chisq'], label=label, alpha=1, density=True, \n",
    "                 bins=np.linspace(np.min(sol['D1_chisq']), np.max(sol['D1_chisq']), nbins))\n",
    "        ax2.hist(sol['D2_chisq'], label=label, alpha=1, density=True, \n",
    "                 bins=np.linspace(np.min(sol['D2_chisq']), np.max(sol['D2_chisq']), nbins))\n",
    "        ax1.axvline(per_99_1, ls='--', lw=3, color='b')\n",
    "        ax2.axvline(per_99_2, ls='--', lw=3, color='b')\n",
    "\n",
    "    for label in sorted(list(set(solutions['model']))):\n",
    "        good = solutions['model'] == label\n",
    "        sol = solutions[good]\n",
    "        alpha=0.4\n",
    "        ax1 = ax12\n",
    "        ax2 = ax22\n",
    "        if correct is not None and label == correct:\n",
    "            continue\n",
    "        rej = np.count_nonzero(sol['D1_chisq'] > per_99_1) / len(sol['D1_chisq'])\n",
    "        ax1.hist(sol['D1_chisq'], label=label + f' rej. {rej*100:.0f}%', alpha=alpha, density=True, \n",
    "                 bins=np.linspace(np.min(sol['D1_chisq']), np.max(sol['D1_chisq']), nbins))\n",
    "#                  bins=np.logspace(np.log10(np.min(sol['D1_chisq'])), np.log10(np.max(sol['D1_chisq'])), 10))\n",
    "        rej = np.count_nonzero(sol['D2_chisq'] > per_99_2) / len(sol['D2_chisq'])\n",
    "        ax2.hist(sol['D2_chisq'], label=label + f' rej. {rej*100:.0f}%', alpha=alpha, density=True, \n",
    "                 bins=np.linspace(np.min(sol['D2_chisq']), np.max(sol['D2_chisq']), nbins))\n",
    "#                  bins=np.logspace(np.log10(np.min(sol['D2_chisq'])), np.log10(np.max(sol['D2_chisq'])), 10))\n",
    "#         axr.hist(sol['ratio_chisq'], label=label, alpha=alpha, density=True)\n",
    "    ax12.axvline(per_99_1, ls='--', lw=3, color='b', label='99% percentile')\n",
    "    ax22.axvline(per_99_2, ls='--', lw=3, color='b', label='99% percentile')\n",
    "\n",
    "    for ax in [ax11, ax12, ax21]:\n",
    "        ax.xaxis.set_visible(False)\n",
    "\n",
    "    for ax in [ax11, ax12, ax21, ax22]:\n",
    "#         ax.loglog()\n",
    "        ax.legend()\n",
    "        ax.semilogx()\n",
    "        ax.axvline(1, ls='--', lw=3, color='k', alpha=0.5)\n",
    "        ax.set_ylabel('Hist. Density')\n",
    "    ax22.set_xlabel(r'$\\chi^2_{\\rm red}$ (~1 indicates good fit)')\n",
    "    ax11.set_xlim([1, None])\n",
    "    return\n",
    "\n",
    "def plot_distributions_double(solutions, correct, label=None, nbins=10):\n",
    "    plt.figure(figsize=(15,15))\n",
    "    plt.suptitle(label)\n",
    "    gs = plt.GridSpec(4, 2, height_ratios=(4, 3, 4, 3), width_ratios=(1, 3), wspace=0.1, hspace=0)\n",
    "    for i in [0, 1]:\n",
    "        ax11 = plt.subplot(gs[0, i])\n",
    "        ax12 = plt.subplot(gs[1, i], sharex=ax11)\n",
    "        ax21 = plt.subplot(gs[2, i], sharex=ax11)\n",
    "        ax22 = plt.subplot(gs[3, i], sharex=ax11)\n",
    "        good = (solutions['D1_chisq'] < 1e32)&(solutions['D2_chisq'] < 1e32)&(solutions['ngood'] >= 4)\n",
    "        solutions = solutions[good]\n",
    "\n",
    "        if correct is not None:\n",
    "            ax1 = ax11\n",
    "            ax2 = ax21\n",
    "            good = solutions['model'] == correct\n",
    "            sol = solutions[good]\n",
    "            per_99_1 = np.percentile(sol['D1_chisq'], 99)\n",
    "            per_99_2 = np.percentile(sol['D2_chisq'], 99)\n",
    "            ax1.hist(sol['D1_chisq'], label=label, alpha=1, density=True, \n",
    "                     bins=np.linspace(np.min(sol['D1_chisq']), np.max(sol['D1_chisq']), nbins))\n",
    "            ax2.hist(sol['D2_chisq'], label=label, alpha=1, density=True, \n",
    "                     bins=np.linspace(np.min(sol['D2_chisq']), np.max(sol['D2_chisq']), nbins))\n",
    "            ax1.axvline(per_99_1, ls='--', lw=3, color='b')\n",
    "            ax2.axvline(per_99_2, ls='--', lw=3, color='b')\n",
    "\n",
    "        for label in sorted(list(set(solutions['model']))):\n",
    "            good = solutions['model'] == label\n",
    "            sol = solutions[good]\n",
    "            alpha=0.4\n",
    "            ax1 = ax12\n",
    "            ax2 = ax22\n",
    "            if correct is not None and label == correct:\n",
    "                continue\n",
    "            rej = np.count_nonzero(sol['D1_chisq'] > per_99_1) / len(sol['D1_chisq'])\n",
    "            ax1.hist(sol['D1_chisq'], label=label + f' rej. {rej*100:.0f}%', alpha=alpha, density=True, \n",
    "                     bins=np.linspace(np.min(sol['D1_chisq']), np.max(sol['D1_chisq']), nbins))\n",
    "    #                  bins=np.logspace(np.log10(np.min(sol['D1_chisq'])), np.log10(np.max(sol['D1_chisq'])), 10))\n",
    "            rej = np.count_nonzero(sol['D2_chisq'] > per_99_2) / len(sol['D2_chisq'])\n",
    "            ax2.hist(sol['D2_chisq'], label=label + f' rej. {rej*100:.0f}%', alpha=alpha, density=True, \n",
    "                     bins=np.linspace(np.min(sol['D2_chisq']), np.max(sol['D2_chisq']), nbins))\n",
    "    #                  bins=np.logspace(np.log10(np.min(sol['D2_chisq'])), np.log10(np.max(sol['D2_chisq'])), 10))\n",
    "    #         axr.hist(sol['ratio_chisq'], label=label, alpha=alpha, density=True)\n",
    "        ax12.axvline(per_99_1, ls='--', lw=3, color='b', label='99% percentile')\n",
    "        ax22.axvline(per_99_2, ls='--', lw=3, color='b', label='99% percentile')\n",
    "    \n",
    "        for ax in [ax11, ax12, ax21]:\n",
    "            ax.xaxis.set_visible(False)\n",
    "\n",
    "        for ax in [ax11, ax12, ax21, ax22]:\n",
    "    #         ax.loglog()\n",
    "            if i == 1:\n",
    "                ax.legend()\n",
    "                ax.semilogx()\n",
    "            ax.axvline(1, ls='--', lw=3, color='k', alpha=0.5)\n",
    "            if i == 0:\n",
    "                ax.set_ylabel('Hist. Density')\n",
    "        ax22.set_xlabel(r'$\\chi^2_{\\rm red}$ (~1 indicates good fit)')\n",
    "        if i == 0:\n",
    "            ax11.set_xlim([0, max(per_99_1 + 1, per_99_2 + 1, 5)])\n",
    "        else:\n",
    "            ax11.set_xlim([1, None])\n",
    "    return\n",
    "\n",
    "solutions_sh510_30 = Table.read('solutions_sh510.csv')\n",
    "ntrials = len(solutions_sh510_30)//6\n",
    "good = solutions_sh510_30['D1_chisq'] > 0\n",
    "solutions_sh510_30 = solutions_sh510_30[good]\n",
    "ngood = len(solutions_sh510_30)//6\n",
    "plot_distributions(solutions_sh510_30, correct='shock_5e10.dat', \n",
    "                   label=f\"Shock 5e10 -- 200 Mpc -- {ntrials} trials ({ntrials - ngood} invalid)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solutions_k04 = Table.read('solutions_k04.csv')\n",
    "ntrials = len(solutions_k04)//6\n",
    "good = solutions_k04['D1_chisq'] > 0\n",
    "solutions_k04 = solutions_k04[good]\n",
    "ngood = len(solutions_k04)//6\n",
    "plot_distributions(solutions_k04, correct='kilonova_0.04.dat', \n",
    "                   label=f\"Kilonova 0.04 -- 130 Mpc -- {ntrials} trials ({ntrials - ngood} invalid)\", nbins=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
